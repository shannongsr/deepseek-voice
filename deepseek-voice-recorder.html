<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="UTF-8">
  <title>DeepSeek 流式语音对话</title>
  <style>
    body { font-family: sans-serif; padding: 20px; }
    #result { white-space: pre-line; margin-top: 10px; }
  </style>
</head>
<body>
  <h2>🎤 与 DeepSeek 流式语音对话</h2>
  <p id="result">正在初始化麦克风...</p>

  <script>
    const resultText = document.getElementById('result');

    let isSpeaking = false;
    let shouldListen = true;
    let mediaRecorder;
    let audioChunks = [];
    let systemPrompt = {
      role: 'system',
      content: '你现在叫做Deepcoke，是一个专门为焦化行业打造的智能语音助手，请你以简洁、口语化、对话感强的风格回答问题。尽量用语音风格表达。'
    };

    async function initMicAndRecord() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);

        mediaRecorder.ondataavailable = e => {
          audioChunks.push(e.data);
        };

        mediaRecorder.onstop = async () => {
          const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
          audioChunks = [];

          resultText.innerText = '⏳ 正在识别...';
          const text = await transcribeWithAssemblyAI(audioBlob);

          resultText.innerText = `你说了：${text}\nDeepcoke 回复：`;
          stopSpeaking();
          await sendStreamToDeepSeek(text);
        };

        startRecording();
      } catch (err) {
        resultText.innerText = '🎤 麦克风权限被拒绝，无法录音';
        console.error('麦克风初始化失败：', err);
      }
    }

    function startRecording() {
      mediaRecorder.start();
      resultText.innerText = '🎙️ 请说话...';
      setTimeout(() => {
        mediaRecorder.stop();
      }, 5000);
    }

    async function transcribeWithAssemblyAI(audioBlob) {
      const uploadResp = await fetch("https://api.assemblyai.com/v2/upload", {
        method: "POST",
        headers: {
          Authorization: "766d722449984affb0edec15ed28fa2b"
        },
        body: audioBlob,
      });

      const uploadData = await uploadResp.json();
      const audio_url = uploadData.upload_url;

      const transcriptReq = await fetch("https://api.assemblyai.com/v2/transcript", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: "766d722449984affb0edec15ed28fa2b"
        },
        body: JSON.stringify({ audio_url, language_code: "zh" })
      });

      const transcriptData = await transcriptReq.json();
      const transcriptId = transcriptData.id;

      while (true) {
        const pollingResp = await fetch(`https://api.assemblyai.com/v2/transcript/${transcriptId}`, {
          headers: {
            Authorization: "766d722449984affb0edec15ed28fa2b"
          }
        });
        const pollingData = await pollingResp.json();

        if (pollingData.status === "completed") {
          return pollingData.text;
        } else if (pollingData.status === "error") {
          throw new Error("AssemblyAI 转录失败");
        }

        await new Promise(res => setTimeout(res, 1000));
      }
    }

    async function sendStreamToDeepSeek(text) {
      const response = await fetch('https://api.deepseek.com/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': 'Bearer sk-c4490148726f4d04a05da9c4aa8dd0a1'
        },
        body: JSON.stringify({
          model: 'deepseek-chat',
          messages: [systemPrompt, { role: 'user', content: text }],
          temperature: 0.8,
          stream: true
        })
      });

      const reader = response.body.getReader();
      const decoder = new TextDecoder('utf-8');
      let buffer = '';
      let speechBuffer = '';
      let tokenCount = 0;

      while (true) {
        const { value, done } = await reader.read();
        if (done) break;
        buffer += decoder.decode(value, { stream: true });

        const lines = buffer.split('\n').filter(line => line.startsWith('data:'));
        for (const line of lines) {
          const jsonStr = line.replace('data: ', '').trim();
          if (jsonStr === '[DONE]') continue;
          try {
            const data = JSON.parse(jsonStr);
            const content = data.choices?.[0]?.delta?.content;
            if (content) {
              resultText.innerText += content;
              speechBuffer += content;
              tokenCount++;

              let splitIndex = Math.max(
                speechBuffer.lastIndexOf("。"),
                speechBuffer.lastIndexOf("！"),
                speechBuffer.lastIndexOf("？")
              );

              if (splitIndex !== -1 || tokenCount >= 10) {
                const sentence =
                  splitIndex !== -1
                    ? speechBuffer.slice(0, splitIndex + 1)
                    : speechBuffer;
                await speakText(sentence);
                speechBuffer = splitIndex !== -1 ? speechBuffer.slice(splitIndex + 1) : '';
                tokenCount = 0;

                await waitAndCheckInterrupt(1000);
              }
            }
          } catch (err) {
            console.error('解析错误：', err);
          }
        }
        buffer = '';
      }

      if (speechBuffer.length > 0) await speakText(speechBuffer);
      startRecording();
    }

    function speakText(text) {
      return new Promise((resolve) => {
        stopSpeaking();

        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = 'zh-CN';
        utterance.pitch = 1.0;
        utterance.rate = 1.0;
        utterance.volume = 1.0;
        utterance.onstart = () => { isSpeaking = true; };
        utterance.onend = () => {
          isSpeaking = false;
          resolve();
        };
        speechSynthesis.speak(utterance);
      });
    }

    function waitAndCheckInterrupt(ms) {
      return new Promise((resolve) => {
        setTimeout(() => {
          resolve();
        }, ms);
      });
    }

    function stopSpeaking() {
      if (speechSynthesis.speaking || speechSynthesis.pending) {
        speechSynthesis.cancel();
        isSpeaking = false;
      }
    }

    window.onload = initMicAndRecord;
  </script>
</body>
</html>
