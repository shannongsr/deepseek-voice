<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="UTF-8">
  <title>DeepSeek æµå¼è¯­éŸ³å¯¹è¯</title>
  <style>
    body { font-family: sans-serif; padding: 20px; }
    #result { white-space: pre-line; margin-top: 10px; }
  </style>
</head>
<body>
  <h2>ğŸ¤ ä¸ DeepSeek æµå¼è¯­éŸ³å¯¹è¯</h2>
  <p id="result">æ­£åœ¨åˆå§‹åŒ–éº¦å…‹é£...</p>

  <script>
    const resultText = document.getElementById('result');

    let isSpeaking = false;
    let shouldListen = true;
    let mediaRecorder;
    let audioChunks = [];
    let systemPrompt = {
      role: 'system',
      content: 'ä½ ç°åœ¨å«åšDeepcokeï¼Œæ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºç„¦åŒ–è¡Œä¸šæ‰“é€ çš„æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ï¼Œè¯·ä½ ä»¥ç®€æ´ã€å£è¯­åŒ–ã€å¯¹è¯æ„Ÿå¼ºçš„é£æ ¼å›ç­”é—®é¢˜ã€‚å°½é‡ç”¨è¯­éŸ³é£æ ¼è¡¨è¾¾ã€‚'
    };

    async function initMicAndRecord() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);

        mediaRecorder.ondataavailable = e => {
          audioChunks.push(e.data);
        };

        mediaRecorder.onstop = async () => {
          const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
          audioChunks = [];

          resultText.innerText = 'â³ æ­£åœ¨è¯†åˆ«...';
          const text = await transcribeWithAssemblyAI(audioBlob);

          resultText.innerText = `ä½ è¯´äº†ï¼š${text}\nDeepcoke å›å¤ï¼š`;
          stopSpeaking();
          await sendStreamToDeepSeek(text);
        };

        startRecording();
      } catch (err) {
        resultText.innerText = 'ğŸ¤ éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œæ— æ³•å½•éŸ³';
        console.error('éº¦å…‹é£åˆå§‹åŒ–å¤±è´¥ï¼š', err);
      }
    }

    function startRecording() {
      mediaRecorder.start();
      resultText.innerText = 'ğŸ™ï¸ è¯·è¯´è¯...';
      setTimeout(() => {
        mediaRecorder.stop();
      }, 5000);
    }

    async function transcribeWithAssemblyAI(audioBlob) {
      const uploadResp = await fetch("https://api.assemblyai.com/v2/upload", {
        method: "POST",
        headers: {
          Authorization: "766d722449984affb0edec15ed28fa2b"
        },
        body: audioBlob,
      });

      const uploadData = await uploadResp.json();
      const audio_url = uploadData.upload_url;

      const transcriptReq = await fetch("https://api.assemblyai.com/v2/transcript", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: "766d722449984affb0edec15ed28fa2b"
        },
        body: JSON.stringify({ audio_url, language_code: "zh" })
      });

      const transcriptData = await transcriptReq.json();
      const transcriptId = transcriptData.id;

      while (true) {
        const pollingResp = await fetch(`https://api.assemblyai.com/v2/transcript/${transcriptId}`, {
          headers: {
            Authorization: "766d722449984affb0edec15ed28fa2b"
          }
        });
        const pollingData = await pollingResp.json();

        if (pollingData.status === "completed") {
          return pollingData.text;
        } else if (pollingData.status === "error") {
          throw new Error("AssemblyAI è½¬å½•å¤±è´¥");
        }

        await new Promise(res => setTimeout(res, 1000));
      }
    }

    async function sendStreamToDeepSeek(text) {
      const response = await fetch('https://api.deepseek.com/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': 'Bearer sk-c4490148726f4d04a05da9c4aa8dd0a1'
        },
        body: JSON.stringify({
          model: 'deepseek-chat',
          messages: [systemPrompt, { role: 'user', content: text }],
          temperature: 0.8,
          stream: true
        })
      });

      const reader = response.body.getReader();
      const decoder = new TextDecoder('utf-8');
      let buffer = '';
      let speechBuffer = '';
      let tokenCount = 0;

      while (true) {
        const { value, done } = await reader.read();
        if (done) break;
        buffer += decoder.decode(value, { stream: true });

        const lines = buffer.split('\n').filter(line => line.startsWith('data:'));
        for (const line of lines) {
          const jsonStr = line.replace('data: ', '').trim();
          if (jsonStr === '[DONE]') continue;
          try {
            const data = JSON.parse(jsonStr);
            const content = data.choices?.[0]?.delta?.content;
            if (content) {
              resultText.innerText += content;
              speechBuffer += content;
              tokenCount++;

              let splitIndex = Math.max(
                speechBuffer.lastIndexOf("ã€‚"),
                speechBuffer.lastIndexOf("ï¼"),
                speechBuffer.lastIndexOf("ï¼Ÿ")
              );

              if (splitIndex !== -1 || tokenCount >= 10) {
                const sentence =
                  splitIndex !== -1
                    ? speechBuffer.slice(0, splitIndex + 1)
                    : speechBuffer;
                await speakText(sentence);
                speechBuffer = splitIndex !== -1 ? speechBuffer.slice(splitIndex + 1) : '';
                tokenCount = 0;

                await waitAndCheckInterrupt(1000);
              }
            }
          } catch (err) {
            console.error('è§£æé”™è¯¯ï¼š', err);
          }
        }
        buffer = '';
      }

      if (speechBuffer.length > 0) await speakText(speechBuffer);
      startRecording();
    }

    function speakText(text) {
      return new Promise((resolve) => {
        stopSpeaking();

        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = 'zh-CN';
        utterance.pitch = 1.0;
        utterance.rate = 1.0;
        utterance.volume = 1.0;
        utterance.onstart = () => { isSpeaking = true; };
        utterance.onend = () => {
          isSpeaking = false;
          resolve();
        };
        speechSynthesis.speak(utterance);
      });
    }

    function waitAndCheckInterrupt(ms) {
      return new Promise((resolve) => {
        setTimeout(() => {
          resolve();
        }, ms);
      });
    }

    function stopSpeaking() {
      if (speechSynthesis.speaking || speechSynthesis.pending) {
        speechSynthesis.cancel();
        isSpeaking = false;
      }
    }

    window.onload = initMicAndRecord;
  </script>
</body>
</html>
